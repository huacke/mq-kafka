
#3.2里的参数，是否开启保护模式，默认开启。要是配置里没有指定bind和密码。
#开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码   和bind，可以开启。否   则最好关闭，设置为no。

protected-mode no

#bind 0.0.0.0

replica-announce-ip 192.168.0.109

replica-announce-port 6379

#redis监听的端口号。
port 6379

#此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度
# 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。

tcp-backlog 511

# 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。
timeout 0

#tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。
#降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。
tcp-keepalive 300

#是否在后台执行，yes：后台运行；no：不是后台运行（老版本默认）
daemonize yes

supervised systemd

#redis的进程文件
pidfile "/var/run/redis_6379.pid"

# 指定日志的记录级别的
# 可以是如下的几个值之一
# debug (尽可能多的日志信息，用于开发和测试之中)
# verbose (少但是有用的信息, 没有debug级别那么混乱)
# notice (适量的信息，用于生产环境)
# warning (只有非常重要和关键的信息会被记录)
loglevel notice

#指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。
logfile "/usr/local/redis/logs/6379.log"

databases 32

#
# 保存 DB 到硬盘:
#
# save <seconds> <changes>
#
# 将会在<seconds> 和 <changes>两个值同时满足时，将DB数据保存到硬盘中
# 其中<seconds> 每多少秒，<changes>是改变的key的数量
#
# 在以下的例子中，将会存在如下的行为
# 当存在最少一个key 变更时，900秒(15分钟)后保存到硬盘
# 当存在最少10个key变更时，300秒后保存到硬盘
# 当存在最少1000个key变更时，60秒后保存到硬盘
#
# 提示: 你可以禁用如下的所有 save 行
#
# 你可以删除所有的save然后设置成如下这样的情况
#
# save ""

save 900 1
save 300 10
save 60 10000

# 作为默认，redis会在RDB快照开启和最近后台保存失败的时候停止接受写入(最少一个保存点)
# 这会使得用户察觉（通常比较困难）到数据不会保持在硬盘上的正确性，否则很难发现
# 这些灾难会发生，如果后台保存程序再次开始工作，reidis会再次自动允许写入
# 然而如果对redis服务器设置了合理持续的监控，那么你可以关闭掉这个选项。
# 这会导致redis将继续进行工作，无论硬盘，权限或者其他的是否有问题
stop-writes-on-bgsave-error yes

# 是否在dump到 rdb 数据库的时候使用LZF来压缩字符串
# 默认是 yes，因为这是一个优良的做法
# 如果你不想耗费你的CPU处理能力，你可以设置为 no，但是这会导致你的数据会很大
rdbcompression yes

# 从RDB的版本5开始，CRC64校验值会写入到文件的末尾
# 这会使得格式化过程中，使得文件的完整性更有保障，
# 但是这会在保存和加载的时候损失不少的性能(大概在10%)
# 你可以关闭这个功能来获得最高的性能
#
# RDB文件会在校验功能关闭的时候，使用0来作为校验值，这将告诉加载代码来跳过校验步骤
rdbchecksum yes

dbfilename "6379.rdb"

dir "/usr/local/redis/data/6379"

# 如果从服务器失去了和主服务器之间的连接，或者当复制仍然处于处理状态的时候
# 从服务器做出如下的两个行为
#
# 1）如果 slave-serve-stale-data 被设置为 yes(默认值)，从服务器将会持续
# 回复来自客户端的请求，可能会回复已经过期的数据，
# 或者返回空的数据，当从服务器第一次异步请求数据时。
#
# 2）如果 slave-serve-stale-data 被设置为 no ，
# 从服务器就会返回"SYNC with master in progress"
# 这个错误，来应答所有命令除了 INFO 和 SLAVEOF
#
replica-serve-stale-data yes

# 你可以配置一个从服务器的实例是否接受写请求，
# 从服务器在存储一些短暂的数据的的时候，接收写请求是一件非常正确的事情
# （因为数据在向主服务器同步之后非常容易擦除）但是会因为配置不正确而导致一些问题
#
# 从redis 2.6开始默认从服务器是只读的服务器
#
# 提示：只读的从服务器并不是设计用来公开给不受信任的互联网客户端的，它
# 仅仅是一个用来防止对实例进行误操作的保护层。只读从服务器默认用来输出管理命令
# 例如 CONFIG, DEBUG 和其他。如果你想限制它的规模，你可以使用'rename-command'来
# 提高它的安全性，使得她作为一个影子来执行管理或者危险的命令

replica-read-only yes

# 是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。
# 如果新的slave连上来或者重连的slave无法部分同步，
# 就会执行全量同步，master会生成rdb文件。
# 有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，
# 再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，
# 直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，
# 多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。
# 在磁盘速度缓慢，网速快的情况下推荐用socket方式。
repl-diskless-sync no

# diskless复制的延迟时间，防止设置为0。一旦复制开始，
# 节点不会再接收新slave的复制请求直到下一个rdb传输。
# 所以最好等待一段时间，等更多的slave连上来。
repl-diskless-sync-delay 5

# 是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。
# 如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，
# 会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，
# 但是在数据量传输很大的场景下，建议选择yes。
repl-disable-tcp-nodelay no

# 当master不可用，Sentinel会根据slave的优先级选举一个master。
# 最低的优先级的slave，当选master。而配置成0，永远不会被选举。
replica-priority 100

masterauth "hq1qaz2wsx#E"

# requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。
# 这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，
# 因为大部分用户也不需要认证。使用requirepass的时候需要注意，因为redis太快了，
# 每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。
requirepass "hq1qaz2wsx#E"

# Command renaming.
#
# 把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，
# 这样用户不能使用，而内部工具还能接着使用。
# 例如
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# 设置成一个空的值，可以禁止一个命令
# rename-command CONFIG ""

# 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。
# 由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，
# 所以maxclients最小建议设置到32。如果超过了maxclients，
# redis会给新的连接发送’max number of clients reached’，并关闭连接。
#
# maxclients 10000

# redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。
# 注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，
# 建议设置的maxmemory需要更小一些。
#
# maxmemory <bytes>

# 内存容量超过maxmemory后的处理策略。
#     volatile-lru：利用LRU算法移除设置过过期时间的key。
#     volatile-random：随机移除设置过过期时间的key。
#     volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）
#     allkeys-lru：利用LRU算法移除任何key。
#     allkeys-random：随机移除任何key。
#     noeviction：不移除任何key，只是返回一个写错误。
# 上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。
# redis将不再接收写请求，只接收get请求。写命令包括：set setnx
#
# maxmemory-policy noeviction

# lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，
# 选出闲置时间最长的key移除。

# maxmemory-samples 5

# 默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。
# 但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，
# Append Only File是另一种持久化方式，可以提供更好的持久化特性。
# Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，
# 每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。
appendonly yes

appendfilename "6379.aof"

# aof持久化策略的配置
# no 表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。
# always 表示每次写入都执行fsync，以保证数据同步到磁盘。
# everysec 表示每秒执行一次fsync，可能会导致丢失这1s数据。
appendfsync everysec

# 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，
# 执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。
# 如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，
# 这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,
# 暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。
# Linux的默认fsync策略是30秒。可能丢失30秒数据。
no-appendfsync-on-rewrite no

# aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，
# 即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。
# 当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，
# 自动启动新的日志重写过程。
auto-aof-rewrite-percentage 100

# 设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写
auto-aof-rewrite-min-size 64mb

#当一个子进程要改写AOF文件，如果以下选项启用，那文件将会在每产生32MB数据时进行同步，这样提交增量文件到磁盘时可以避免出现比较大的延迟。
aof-rewrite-incremental-fsync yes

# aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。
# 重启可能发生在redis所在的主机操作系统宕机后，
# 尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）
# 出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，
# 当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。
# 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。
aof-load-truncated yes

# Lua脚本的最大超时时间.
#
# 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。
# 当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。
# 第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。
lua-time-limit 5000

# slog log是用来记录redis运行中执行比较慢的命令耗时。
# 当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。
# 执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，
# 单位是微秒，所以1000000就是1秒。
# 注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。

slowlog-log-slower-than 10000

# 慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。
# 这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存
slowlog-max-len 128

# 延迟监控功能是用来监控redis中执行比较缓慢的一些操作，
# 用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。
# 0的话，就是关闭监视。默认延迟监控功能是关闭的，
# 如果你需要打开，也可以通过CONFIG SET命令动态设置。
latency-monitor-threshold 0

# 键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。
# 因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。
# notify-keyspace-events 的参数可以是以下字符的任意组合，
# 它指定了服务器该发送哪些类型的通知：
# K 键空间通知，所有通知以 __keyspace@__ 为前缀
# E 键事件通知，所有通知以 __keyevent@__ 为前缀
# g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知
# $ 字符串命令的通知
# l 列表命令的通知
# s 集合命令的通知
# h 哈希命令的通知
# z 有序集合命令的通知
# x 过期事件：每当有过期键被删除时发送
# e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送
# A 参数 g$lshzxe 的别名
# 输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。
notify-keyspace-events ""

# 数据量小于等于hash-max-ziplist-entries的用ziplist，
# 大于hash-max-ziplist-entries用hash
# value大小小于等于hash-max-ziplist-value的用ziplist，
# 大于hash-max-ziplist-value用hash。
hash-max-ziplist-entries 512
hash-max-ziplist-value 64

list-max-ziplist-size -2

list-compress-depth 0

# 数据量小于等于set-max-intset-entries用iniset，
# 大于set-max-intset-entries用set。
set-max-intset-entries 512

# 数据量小于等于zset-max-ziplist-entries用ziplist，
# 大于zset-max-ziplist-entries用zset
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

hll-sparse-max-bytes 3000

activerehashing yes

client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

#redis使用一个内部程序来处理后台任务，例如关闭超时的client连接，清除过期的key等等。它并不会同时处理所有的任务，redis通过指定的hz参数去检查和执行任务。
#hz默认设为10，提高它的值将会占用更多的cpu，当然相应的redis将会更快的处理同时到期的许多key，以及更精确的去处理超时。
#hz的取值范围是1~500，通常不建议超过100，只有在请求延时非常低的情况下可以将值提升到100。
hz 10

# Generated by CONFIG REWRITE

replicaof 192.168.0.109  6379

